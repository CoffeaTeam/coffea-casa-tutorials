{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "blocked-chemical",
   "metadata": {},
   "source": [
    "In this demo, we first show how to use the Arrow `Dataset` API `SkyhookFileFormat` API to scan parquet files by pushing down scan opertations into Ceph and then we show how to use the `Dataset` API to process parquet files containing NanoEvents stored in Ceph in parallel through Coffea using Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medieval-profile",
   "metadata": {},
   "source": [
    "## Exploring SkyhookFileFormat with PyArrow\n",
    "\n",
    "We import the Dataset API and the Parquet API from PyArrow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fifty-syndrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow\n",
    "import pyarrow.dataset as ds\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inappropriate-watts",
   "metadata": {},
   "source": [
    "Now, we will instantiate the `SkyhookFileFormat`. Upon instantiation, the connection to the Ceph cluster is made under the hood. The connection is closed automatically upon object destruction. The `SkyhookFileFormat` API currently takes the Ceph configuration file as input. It inherits from the `FileFormat` API and uses the `DirectObjectAccess` API under the hood to interact with the underlying objects that make up a file in CephFS. Since, we mount CephFS, we use the `FileSystemDataset` that comes out of the box with Apache Arrow for instantiating our dataset, as by mounting CephFS we have just another directory of Parquet files. Having the suitability of using the `FileSystemDataset`, we just can start pushing down scan operations to our Parquet files by just plugging in `SkyhookFileFormat` in the format paramter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aerial-helping",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyarrow.dataset' has no attribute 'SkyhookFileFormat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_655/30402110.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file:///mnt/cephfs/nyc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSkyhookFileFormat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"parquet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/opt/ceph/ceph.conf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cephfs-data0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pyarrow/dataset.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_orc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     raise AttributeError(\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;34m\"module 'pyarrow.dataset' has no attribute '{0}'\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyarrow.dataset' has no attribute 'SkyhookFileFormat'"
     ]
    }
   ],
   "source": [
    "dataset = ds.dataset(\"file:///mnt/cephfs/nyc\", format=ds.SkyhookFileFormat(\"parquet\", \"/opt/ceph/ceph.conf\", \"cephfs-data0\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "received-costa",
   "metadata": {},
   "source": [
    "Now we apply some projections and filters on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "romance-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_amount</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.84</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69.99</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.84</td>\n",
       "      <td>53.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68.50</td>\n",
       "      <td>53.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.01</td>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>78.88</td>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>64.84</td>\n",
       "      <td>58.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>0.31</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>58.80</td>\n",
       "      <td>57.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>229.80</td>\n",
       "      <td>228.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>381 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     total_amount  fare_amount\n",
       "0           75.84        52.00\n",
       "1           69.99        52.00\n",
       "2           59.84        53.00\n",
       "3           68.50        53.50\n",
       "4           70.01        52.00\n",
       "..            ...          ...\n",
       "376         78.88        67.00\n",
       "377         64.84        58.50\n",
       "378          0.31         0.01\n",
       "379         58.80        57.50\n",
       "380        229.80       228.50\n",
       "\n",
       "[381 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_table(columns=[\"total_amount\", \"fare_amount\"], filter=(ds.field(\"trip_distance\") > 20.0)).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "concerned-therapy",
   "metadata": {},
   "source": [
    "## Import the required modules\n",
    "\n",
    "Import `uproot`, `awkward`, `coffea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "hollow-genre",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Numba needs NumPy 1.21 or less",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muproot\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mawkward\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mak\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NanoEventsFactory, NanoAODSchema\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m processor, hist\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/nanoevents/__init__.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"NanoEvents and helpers\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfactory\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m NanoEventsFactory\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     BaseSchema,\n\u001b[1;32m      7\u001b[0m     NanoAODSchema,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     PDUNESchema,\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNanoEventsFactory\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBaseSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDUNESchema\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     24\u001b[0m ]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/nanoevents/factory.py:10\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mawkward\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01muproot\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     CachedMapping,\n\u001b[1;32m     12\u001b[0m     ParquetSourceMapping,\n\u001b[1;32m     13\u001b[0m     PreloadedOpener,\n\u001b[1;32m     14\u001b[0m     PreloadedSourceMapping,\n\u001b[1;32m     15\u001b[0m     TrivialParquetOpener,\n\u001b[1;32m     16\u001b[0m     TrivialUprootOpener,\n\u001b[1;32m     17\u001b[0m     UprootSourceMapping,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschemas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSchema, NanoAODSchema\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m key_to_tuple, tuple_to_key\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/nanoevents/mapping/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01muproot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrivialUprootOpener, UprootSourceMapping\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TrivialParquetOpener, ParquetSourceMapping\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreloaded\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      4\u001b[0m     SimplePreloadedColumnSource,\n\u001b[1;32m      5\u001b[0m     PreloadedOpener,\n\u001b[1;32m      6\u001b[0m     PreloadedSourceMapping,\n\u001b[1;32m      7\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/nanoevents/mapping/uproot.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mawkward\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UUIDOpener, BaseSourceMapping\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m quote, tuple_to_key\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTrivialUprootOpener\u001b[39;00m(UUIDOpener):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/nanoevents/mapping/base.py:5\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mabc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Mapping\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m key_to_tuple, tuple_to_key\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mUUIDOpener\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/nanoevents/transforms.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mawkward\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcoffea\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnanoevents\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m concat\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/numba/__init__.py:200\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    199\u001b[0m _ensure_llvm()\n\u001b[0;32m--> 200\u001b[0m \u001b[43m_ensure_critical_deps\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# we know llvmlite is working as the above tests passed, import it now as SVML\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# needs to mutate runtime options (sets the `-vector-library`).\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mllvmlite\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/numba/__init__.py:140\u001b[0m, in \u001b[0;36m_ensure_critical_deps\u001b[0;34m()\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.18 or greater\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m numpy_version \u001b[38;5;241m>\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m21\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumba needs NumPy 1.21 or less\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Numba needs NumPy 1.21 or less"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "import awkward as ak\n",
    "from coffea.nanoevents import NanoEventsFactory, NanoAODSchema\n",
    "from coffea import processor, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manual-disposition",
   "metadata": {},
   "source": [
    "## Define a Processor instance\n",
    "\n",
    "The processor implementation given below has been taken from [here](https://github.com/CoffeaTeam/coffea/blob/master/binder/nanoevents.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "domestic-interim",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyZPeak(processor.ProcessorABC):\n",
    "    def __init__(self):\n",
    "        self._histo = hist.Hist(\n",
    "            \"Events\",\n",
    "            hist.Cat(\"dataset\", \"Dataset\"),\n",
    "            hist.Bin(\"mass\", \"Z mass\", 60, 60, 120),\n",
    "        )\n",
    "    \n",
    "    @property\n",
    "    def accumulator(self):\n",
    "        return self._histo\n",
    "    \n",
    "    # we will receive a NanoEvents instead of a coffea DataFrame\n",
    "    def process(self, events):\n",
    "        out = self.accumulator.identity()\n",
    "        mmevents = events[\n",
    "            (ak.num(events.Muon) == 2)\n",
    "            & (ak.sum(events.Muon.charge, axis=1) == 0)\n",
    "        ]\n",
    "        zmm = mmevents.Muon[:, 0] + mmevents.Muon[:, 1]\n",
    "        out.fill(\n",
    "            dataset=events.metadata[\"dataset\"],\n",
    "            mass=zmm.mass,\n",
    "        )\n",
    "        return out\n",
    "    \n",
    "    def postprocess(self, accumulator):\n",
    "        return accumulator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-assist",
   "metadata": {},
   "source": [
    "## Write some NanoEvents Parquet files to CephFS\n",
    "\n",
    "Here we populate the CephFS mounted directory with the parquet files created in the previous step. In this version, we need to make sure that the individual file sizes is under 4MB which is the default object size of Ceph to ensure one-to-one mapping of files to objects, which is a requirement in the multiple-file design that we have now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "muslim-retrieval",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ak.to_parquet(\n",
    "    uproot.lazy(\"nano_dy.root:Events\"),\n",
    "    \"nano_dy.parquet\",\n",
    "    list_to32=True,\n",
    "    use_dictionary=False,\n",
    "    compression=\"GZIP\",\n",
    "    compression_level=1,\n",
    ")\n",
    "\n",
    "ak.to_parquet(\n",
    "    uproot.lazy(\"nano_dimuon.root:Events\"),\n",
    "    \"nano_dimuon.parquet\",\n",
    "    list_to32=True,\n",
    "    use_dictionary=False,\n",
    "    compression=\"GZIP\",\n",
    "    compression_level=1,\n",
    ")\n",
    "\n",
    "os.makedirs(\"/mnt/cephfs/nanoevents/ZJets\", exist_ok=True)\n",
    "os.makedirs(\"/mnt/cephfs/nanoevents/Data\", exist_ok=True)\n",
    "for i in range(5):\n",
    "    os.system(f\"cp nano_dy.parquet /mnt/cephfs/nanoevents/ZJets/nano_dy.{i}.parquet\")\n",
    "    os.system(f\"cp nano_dimuon.parquet /mnt/cephfs/nanoevents/Data/nano_dimuon.{i}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ready-channels",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "nano_dimuon.0.parquet  nano_dimuon.3.parquet  nano_dimuon.parquet\n",
      "nano_dimuon.1.parquet  nano_dimuon.4.parquet\n",
      "nano_dimuon.2.parquet  nano_dimuon.5.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/cephfs/nanoevents/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "christian-upset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /opt/conda/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "nano_dy.0.parquet  nano_dy.2.parquet  nano_dy.4.parquet\n",
      "nano_dy.1.parquet  nano_dy.3.parquet  nano_dy.parquet\n"
     ]
    }
   ],
   "source": [
    "!ls /mnt/cephfs/nanoevents/ZJets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-yorkshire",
   "metadata": {},
   "source": [
    "## Reading Nanoevents using SkyhookFileFormat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_skyhook = NanoEventsFactory.from_parquet(\"/mnt/cephfs/nanoevents/ZJets/nano_dy.0.parquet\", skyhook_options = {\"ceph_config_path\": \"/opt/ceph/ceph.conf\", \"ceph_data_pool\": \"cephfs_data0\"}).events()\n",
    "ak.flatten([events_skyhook.Muon[i].pt for i in range(len(events_skyhook.Muon)) if len(events_skyhook.Muon[i])]).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-america",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running a job in parallel using Dask\n",
    "\n",
    "The `LocalCluster()` used below creates a process pool with worker count equal to the number of cores available to the Notebook where each worker is single-threaded. The `LocalCluster` can be replaced by other cluster resource managers provided by Dask Distributed like `KuberneresCluster`, `YarnCluster`, etc. Here, we create a `LocalCluster` and get a client handle to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ce57d91-8962-4328-b89f-e8bc3edc299b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-56c38610-8a93-11ec-82a9-3679a7cb68f6</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Direct</td>\n",
       "            <td style=\"text-align: left;\"></td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"/user/oksana.shadura@cern.ch/proxy/8787/status\" target=\"_blank\">/user/oksana.shadura@cern.ch/proxy/8787/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Scheduler Info</h3></summary>\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-8fb6c67f-e942-4d85-9e2b-86e6666f8de0</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:35507\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 1\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"/user/oksana.shadura@cern.ch/proxy/8787/status\" target=\"_blank\">/user/oksana.shadura@cern.ch/proxy/8787/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 6\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> 1 minute ago\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 23.42 GiB\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:36480\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 6\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"/user/oksana.shadura@cern.ch/proxy/38067/status\" target=\"_blank\">/user/oksana.shadura@cern.ch/proxy/38067/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 23.42 GiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:40557\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /home/cms-jovyan/dask-worker-space/worker-i2oiu_xt\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks executing: </strong> 0\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in memory: </strong> 0\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks ready: </strong> 0\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Tasks in flight: </strong>0\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>CPU usage:</strong> 2.0%\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Last seen: </strong> Just now\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory usage: </strong> 132.79 MiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Spilled bytes: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Read bytes: </strong> 14.02 kiB\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Write bytes: </strong> 18.01 kiB\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:35507' processes=1 threads=6, memory=23.42 GiB>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:35507\")\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-empty",
   "metadata": {},
   "source": [
    "We have added a new function called `run_parquet_job` to the executor API in coffea to run jobs on Parquet files using the Arrow Dataset API under the hood. \n",
    "This API takes an optional `ceph_config_path` parameter, which is basically the path to the configuration file of the Ceph cluster and instructs this function to read from RADOS using the `SkyhookFileFormat` (which allows pushdown) instead of the out of the box `ParquetFormat` API . This API also allows just passing a single directory path and the Datasets API does the dataset discovery task by itself. The calls to the Dataset API are launced in parallel and there will one Dataset API call per file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "altered-transition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('database or disk is full')).History will not be written to the database.\n",
      "[##                                      ] | 6% Completed |  8.0s\r"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Work item WorkItem(dataset='Data', filename='/opt/ceph/ceph.conf:cephfs_data0:/mnt/cephfs/nanoevents/Data/nano_dimuon.parquet', treename='Events', entrystart=0, entrystop=0, fileuuid='', usermeta=None) caused a KilledWorker exception (likely a segfault or out-of-memory issue)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKilledWorker\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:735\u001b[0m, in \u001b[0;36mDaskExecutor.__call__\u001b[0;34m(self, items, function, accumulator)\u001b[0m\n\u001b[1;32m    730\u001b[0m         progress(work, multi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, notebook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accumulate(\n\u001b[1;32m    732\u001b[0m         [\n\u001b[1;32m    733\u001b[0m             work\u001b[38;5;241m.\u001b[39mresult()\n\u001b[1;32m    734\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 735\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m _decompress(\u001b[43mwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    736\u001b[0m         ],\n\u001b[1;32m    737\u001b[0m         accumulator,\n\u001b[1;32m    738\u001b[0m     )\n\u001b[1;32m    739\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m KilledWorker \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/distributed/client.py:275\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    274\u001b[0m     typ, exc, tb \u001b[38;5;241m=\u001b[39m result\n\u001b[0;32m--> 275\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancelled\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKilledWorker\u001b[0m: ('MyZPeak-4c349eb482d49d2afffd7b07255efab8', <WorkerState 'tcp://127.0.0.1:46405', name: 0, status: closed, memory: 0, processing: 13>)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:1366\u001b[0m, in \u001b[0;36mRunner.__call__\u001b[0;34m(self, fileset, treename, processor_instance)\u001b[0m\n\u001b[1;32m   1361\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\n\u001b[1;32m   1362\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautomatic_retries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretries, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskipbadfiles, closure\n\u001b[1;32m   1363\u001b[0m )\n\u001b[1;32m   1365\u001b[0m executor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecutor\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mexe_args)\n\u001b[0;32m-> 1366\u001b[0m wrapped_out \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1368\u001b[0m processor_instance\u001b[38;5;241m.\u001b[39mpostprocess(wrapped_out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msavemetrics \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_dataframes:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/coffea/processor/executor.py:743\u001b[0m, in \u001b[0;36mDaskExecutor.__call__\u001b[0;34m(self, items, function, accumulator)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheavy_input \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baditem, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    742\u001b[0m             baditem \u001b[38;5;241m=\u001b[39m baditem[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m--> 743\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    744\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWork item \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbaditem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m caused a KilledWorker exception (likely a segfault or out-of-memory issue)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    745\u001b[0m         )\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Work item WorkItem(dataset='Data', filename='/opt/ceph/ceph.conf:cephfs_data0:/mnt/cephfs/nanoevents/Data/nano_dimuon.parquet', treename='Events', entrystart=0, entrystop=0, fileuuid='', usermeta=None) caused a KilledWorker exception (likely a segfault or out-of-memory issue)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import schemas\n",
    "\n",
    "executor = processor.DaskExecutor(client=client)\n",
    "\n",
    "run = processor.Runner(\n",
    "    executor=executor,\n",
    "    use_skyhook=True,\n",
    "    savemetrics=True,\n",
    "    skyhook_options = {\"ceph_config_path\": \"/opt/ceph/ceph.conf\", \"ceph_data_pool\": \"cephfs_data0\"},\n",
    "    format=\"parquet\",\n",
    "    schema=schemas.NanoAODSchema,\n",
    ")\n",
    "\n",
    "hists = run(\n",
    "    {\n",
    "        \"ZJets\": \"/mnt/cephfs/nanoevents/ZJets\",\n",
    "        \"Data\": \"/mnt/cephfs/nanoevents/Data\",\n",
    "    },\n",
    "    \"Events\",\n",
    "    processor_instance=MyZPeak(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-worst",
   "metadata": {},
   "source": [
    "## Running iteratively using the `iterative_executor`\n",
    "\n",
    "Run the same job again, but now iteratively. The calls to the Dataset API will now be sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39775511b2d545fdad310d7453891dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing:   0%|          | 0/13 [00:00<?, ?chunk/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "from coffea import processor\n",
    "from coffea.nanoevents import schemas\n",
    "\n",
    "executor = processor.IterativeExecutor()\n",
    "\n",
    "run = processor.Runner(\n",
    "    executor=executor,\n",
    "    use_skyhook=True,\n",
    "    savemetrics=True,\n",
    "    skyhook_options = {\"ceph_config_path\": \"/opt/ceph/ceph.conf\", \"ceph_data_pool\": \"cephfs_data0\"},\n",
    "    format=\"parquet\",\n",
    "    schema=schemas.NanoAODSchema,\n",
    ")\n",
    "\n",
    "hists = run(\n",
    "    {\n",
    "        \"ZJets\": \"/mnt/cephfs/nanoevents/ZJets\",\n",
    "        \"Data\": \"/mnt/cephfs/nanoevents/Data\",\n",
    "    },\n",
    "    \"Events\",\n",
    "    processor_instance=MyZPeak(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef6a420-8718-4be3-ab2a-b1a3685b8c30",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running iteratively without Skyhook `iterative_executor`\n",
    "\n",
    "Run the same job again, but now iteratively without Skyhook. The calls to the Dataset API will now be sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4551f3e-1679-4bc8-baa2-49cb629be7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "executor = processor.IterativeExecutor()\n",
    "\n",
    "run = processor.Runner(\n",
    "    executor=executor,\n",
    "    use_skyhook=False,\n",
    "    savemetrics=True,\n",
    "    skyhook_options = {\"ceph_config_path\": \"/opt/ceph/ceph.conf\", \"ceph_data_pool\": \"cephfs_data0\"},\n",
    "    format=\"parquet\",\n",
    "    schema=schemas.NanoAODSchema,\n",
    ")\n",
    "\n",
    "hists = run(\n",
    "    {\n",
    "        \"ZJets\": \"/mnt/cephfs/nanoevents/ZJets\",\n",
    "        \"Data\": \"/mnt/cephfs/nanoevents/Data\",\n",
    "    },\n",
    "    \"Events\",\n",
    "    processor_instance=MyZPeak(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consolidated-panel",
   "metadata": {},
   "source": [
    "As expected, much slower than running using Dask."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-petroleum",
   "metadata": {},
   "source": [
    "## Plotting the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "hist.plot1d(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
